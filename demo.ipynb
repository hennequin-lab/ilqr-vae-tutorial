{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iLQR-VAE tutorial \n",
    "\n",
    "In this tutorial, we will do the following : \n",
    "\n",
    "* Introduce the iLQR-VAE model\n",
    "* Example of the inference of models pre and post-training on the Maze dataset\n",
    "* Illustration of the flexibility of the inference model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iLQR-VAE overview\n",
    "\n",
    "### Generative process \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"figures/generative.png\" width=\"70%\"/>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* **Input-driven** latent state dynamics : $\\mathbf{z}_{t+1} = f_\\theta(\\mathbf{z}_t, \\mathbf{u}_t, t)$\n",
    "\n",
    "* Likelihood given latents : $\\mathbf{o}_t | \\mathbf{z}_t \\sim p_\\theta(\\mathbf{o}_t | \\mathbf{z}_t)$\n",
    "\n",
    "* Student prior over the inputs (favouring *sparse inputs*) : $u_{it} = s_i \\epsilon_{it} \\sqrt{\\nu/\\alpha_t}$ with a special Gaussian prior for the initial input (setting initial condition)\n",
    "\n",
    "* $\\mathbf{u}_t \\in \\mathbb{R}^m$, $\\mathbf{z}_t \\in \\mathbb{R}^n$ and $\\mathbf{o}_t \\in \\mathbb{R}^{n_o}$\n",
    "\n",
    "* No bottleneck\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equations\n",
    "\n",
    "### Inference\n",
    "To train the model, we optimize $\\theta$ to maximize the marginal log-likelihood of observing a collection of independent observation sequences $\\mathbf{\\mathcal{O}} = \\{ \\mathbf{o}^{(1)}, \\ldots, \\mathbf{o}^{(K)} \\}$ (trials) given by:\n",
    "$$\n",
    "    \\log p_\\theta(\\mathbf{\\mathcal{O}})\n",
    "    =\n",
    "    \\sum_{k=1}^K\n",
    "    \\log \\int\n",
    "    p_\\theta(\\mathbf{o}^{(k)} |\\mathbf{z}(\\mathbf{u}))\n",
    "    p_\\theta(\\mathbf{u})\\,\n",
    "    d \\mathbf{u}\n",
    "$$\n",
    "\n",
    "This is intractable, so we instead maximize a lower-bound on this :\n",
    "$$\\mathcal{L}(\\mathbf{\\mathcal{O}}, \\theta, \\phi) =\n",
    "    \\sum_k\n",
    "    \\mathbb{E}_{q_\\phi(\\mathbf{u}|\\mathbf{o}^{(k)})}\n",
    "    \\left [\n",
    "        \\log p_\\theta(\\mathbf{o}^{(k)} | \\mathbf{u})\n",
    "        +\n",
    "        \\log p_\\theta(\\mathbf{u})\n",
    "        -\n",
    "        \\log q_\\phi(\\mathbf{u}|\\mathbf{o}^{(k)})\n",
    "        \\right] =\n",
    "    \\sum_k\n",
    "    \\mathbb{E}_{q_\\phi(\\mathbf{u}|\\mathbf{o}^{(k)})}\n",
    "    \\left [\n",
    "        \\sum_{t=1}^T\n",
    "        \\log p_\\theta(\\mathbf{o}_t^{(k)} | \\mathbf{z}_t)\n",
    "        +\n",
    "        \\log p_\\theta(\\mathbf{u}_t)\n",
    "        -\n",
    "        \\log q_\\phi(\\mathbf{u}_t|\\mathbf{o}^{(k)}) \\right]           \\\\\n",
    "        \\leq \\log p_\\theta(\\mathbf{\\mathcal{O}}).$$\n",
    "\n",
    "We need an expression for $\\log q_\\phi(\\mathbf{u}_t|\\mathbf{o}^{(k)})$ : one way is to use a Gaussian approximation parameterized with RNNs (as in LFADS). Here, we instead use an *optimization-based* inference module. \n",
    "\n",
    "We parametrize the mean of the approximate posterior using the inputs *maximizing the exact log posterior*, i.e. \n",
    "        \n",
    " $$\\mathbf{u}^\\star(\\mathbf{o}^{(k)})\n",
    "      = \\underset{\\mathbf{u}}{\\text{argmax}}\\: \\log p_\\theta(\\mathbf{u}|\\mathbf{o}^{(k)}) \\\\\n",
    "      = \\underset{\\mathbf{u}}{\\text{argmax}} \\left[\n",
    "        \\sum_{t=1}^T \\log p_\\theta(\\mathbf{o}_t^{(k)} | \\mathbf{u})\n",
    "        + \\log p_\\theta(\\mathbf{u}_t)\n",
    "        \\right]$$\n",
    "        \n",
    "We find these using **iLQR**, such that \n",
    "$\\mathbf{u}^\\star(\\mathbf{o}) =\n",
    "    \\text{iLQRsolve}(\\mathbf{o}, \\theta).$\n",
    "    \n",
    "    \n",
    "This has the advantage that we don't need to introduce new parameters for the inference (at least for the mean), and reduces the number of hyperparameters to optimize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model\n",
    "\n",
    "<img src=\"figures/model.pdf\" width=\"70%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_output \"dune top\"\n",
    "\n",
    "open Owl\n",
    "open Ilqr_vae\n",
    "open Tutorial_lib\n",
    "open Gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(*load model parameters\n",
    "perform inference on unseen data \n",
    "show iterations of ilqr \n",
    "Overall structure :\n",
    "- presentation of the model with the plot (5min)\n",
    "- highlight the key difference with LFADS (2min)\n",
    "- brief overview of the training (not done here) (2min)\n",
    "- illustration of the inference on the monkey Maze data \n",
    "-> show inference on training data\n",
    "-> show how we directly get the co-smoothing by cutting the matrix\n",
    "-> highlight how we can also do inference on a shorter/longer chunk if we throw away the uncertainty \n",
    "\n",
    "\n",
    "\n",
    "TO DO : \n",
    "[x] Show co-smoothing etc\n",
    "[x] Show inference on longer or shorter chunk (if we want)\n",
    "[ ] Show parameters of the RNN\n",
    "[ ] Prepare the \"slides'/pictures showing a description of the model\n",
    "[ ] Consider adding plots of the Duffing?\n",
    "\n",
    "*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the generative model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type setup =\n",
    "  { n : int\n",
    "  ; m : int\n",
    "  ; n_trials : int\n",
    "  ; n_steps : int\n",
    "  ; n_neural : int\n",
    "  }\n",
    "\n",
    "let n = 90\n",
    "let m = 15\n",
    "let dt = 5E-3\n",
    "let n_neurons = 137\n",
    "let n_beg = n / m\n",
    "let setup = { n; m; n_trials = 1; n_steps = 140; n_neural = n_neurons }\n",
    "\n",
    "(* Define the prior*)\n",
    "module U = Prior.Student (struct\n",
    "  let n_beg = n / m\n",
    "  let m = m\n",
    "end)\n",
    "\n",
    "(*Choose the type of likelihood (e.g Poisson for spikes, Gaussian for calcium imaging)*)\n",
    "module L = Likelihood.Poisson (struct\n",
    "  let label = \"neural\"\n",
    "  let dt = AD.F dt\n",
    "  let link_function = AD.Maths.exp\n",
    "  let d_link_function = AD.Maths.exp\n",
    "  let d2_link_function = AD.Maths.exp\n",
    "  let n_output = n_neurons\n",
    "  let n = n\n",
    "end)\n",
    "\n",
    "(*Choose the dynamics (e.g GRU RNN)*)\n",
    "module D = Dynamics.Mini_GRU_IO (struct\n",
    "  let phi x = AD.Maths.(AD.requad x - F 1.)\n",
    "  let d_phi x = AD.d_requad x\n",
    "  let sigma x = AD.Maths.sigmoid x\n",
    "  let d_sigma x = AD.Maths.(exp (neg x) / sqr (F 1. + exp (neg x)))\n",
    "  let m = m\n",
    "  let n = n\n",
    "  let n_beg = Some (n / m)\n",
    "end)\n",
    "\n",
    "(*define the hyperparameters for this dataset : latent space dimension n, number of input channels m *)\n",
    "module X = struct\n",
    "  let n = setup.n\n",
    "  let m = setup.m\n",
    "  let n_steps = setup.n_steps\n",
    "  let diag_time_cov = false\n",
    "  let n_beg = n_beg\n",
    "end\n",
    "\n",
    "let () = Jupyter_notebook.clear_output ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module Make_model\n",
    "    (U : Prior.T)\n",
    "    (D : Dynamics.T)\n",
    "    (L : Likelihood.T) (S : sig\n",
    "      val n_steps : int\n",
    "    end) =\n",
    "struct\n",
    "  module G = Generative.Make (U) (D) (L)\n",
    "\n",
    "  (* here we use ILQR as the recognition model, but our codebase\n",
    "     allows substituting this with e.g. biRNNs, yielding a model\n",
    "     similar to LFADS *)\n",
    "  module R =\n",
    "    Recognition.ILQR (U) (D) (L)\n",
    "      (struct\n",
    "        let conv_threshold = 1E-6\n",
    "        let reuse_u = `never\n",
    "        let diag_time_cov = false\n",
    "        let n_steps = S.n_steps\n",
    "      end)\n",
    "\n",
    "  module Model = Vae.Make (G) (R)\n",
    "end\n",
    "\n",
    "module Model = Make_model (U) (D) (L) (X)\n",
    "\n",
    "let () = Jupyter_notebook.clear_output ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open Owl_parameters\n",
    "open Base\n",
    "open Vae\n",
    "\n",
    "let train_spikes = Arr.load_npy \"nlb/train_spikes_0.npy\"\n",
    "let n_train_neurons = 137\n",
    "let n_test_neurons = 45\n",
    "let n_neurons = n_train_neurons + n_test_neurons\n",
    "\n",
    "let trial =\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let x =\n",
    "    Arr.get_slice [ [ 0 ] ] train_spikes |> fun z -> Arr.reshape z [| -1; n_neurons |]\n",
    "  in\n",
    "  let o = AD.pack_arr x in\n",
    "  Data.pack o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let spikes_to_plot =\n",
    "  Arr.get_slice [ [ 0 ] ] train_spikes |> fun z -> Arr.reshape z [| -1; n_neurons |]\n",
    "\n",
    "let () =\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 182 (fun i ->\n",
    "           let st = \"p pt 7 ps 0.2 lc black\" in\n",
    "           let fi = Float.of_int i in\n",
    "           let arr = Arr.get_slice [ []; [ i ] ] spikes_to_plot in\n",
    "           let arr = Arr.(fi $* arr) in\n",
    "           item (A arr) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"neuron\"; yrange (1., 182.) ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model : \n",
    "* We need to learn the **generative** parameters of the model and the **posterior covariance**\n",
    "* This is done by optimizing the ELBO\n",
    "* To train the model, we use Adam with a sqrt decaying learning rate (to be optimized)\n",
    "* The training is parallelized over CPUs and typically takes ~6-8h on 168 CPUs with a batch size of 168 \n",
    "* Here, we will load a pre-trained model and show how iLQR works as an inference module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include Vae_typ\n",
    "open Vae_typ.P\n",
    "open Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to return the mean firing rates + inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let get_us_and_rates gen_prms prms trial =\n",
    "  let u_mean, all_us, zs =\n",
    "    let u_mean, all_us =\n",
    "      R.posterior_mean ~gen_prms:prms.generative prms.recognition trial\n",
    "    in\n",
    "    let u = AD.Maths.reshape u_mean [| 1; -1; AD.Mat.col_num u_mean |] in\n",
    "    let zs = G.integrate ~prms:prms.generative ~u in\n",
    "    (*this is of size n_samples x n-steps x n_output *)\n",
    "    let remove_n_beg = AD.Maths.get_slice [ []; [ G.n_beg - 1; -1 ] ] in\n",
    "    remove_n_beg u_mean, all_us, remove_n_beg zs\n",
    "  in\n",
    "  let z_mean =\n",
    "    Arr.mean ~axis:0 (AD.unpack_arr zs)\n",
    "    |> fun x -> Arr.reshape x [| -1; (Arr.shape x).(2) |]\n",
    "  in\n",
    "  let z_mean = AD.pack_arr z_mean in\n",
    "  let open Vae_typ.P in\n",
    "  let open Prior_typ in\n",
    "  let open Generative_typ.P in\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let c = Owl_parameters.extract gen_prms.generative.likelihood.c in\n",
    "  let bias = Owl_parameters.extract gen_prms.generative.likelihood.bias in\n",
    "  let gain = Owl_parameters.extract gen_prms.generative.likelihood.gain in\n",
    "  AD.Maths.(gain * exp ((z_mean *@ transpose c) + bias)) |> AD.unpack_arr, all_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open Generative.P\n",
    "\n",
    "(*load random set of initial parameters and plot the dynamics/readout*)\n",
    "\n",
    "let prms = Misc.load_bin \"progress_0.params.bin\"\n",
    "\n",
    "let uf =\n",
    "  let open Dynamics.Mini_GRU_IO_P in\n",
    "  Owl_parameters.extract prms.generative.dynamics.uf |> AD.unpack_arr\n",
    "\n",
    "let c =\n",
    "  let open Likelihood.Poisson_P in\n",
    "  Owl_parameters.extract prms.generative.likelihood.c |> AD.unpack_arr\n",
    "\n",
    "let figure (module P : Plot) =\n",
    "  P.heatmap\n",
    "    (`mat uf)\n",
    "    ~style:\"image pixels\"\n",
    "    ([ barebone ] @ [ title \"Uf\" ] @ [ xlabel \"n\" ] @ [ ylabel \"n\" ] @ [ cbtics `auto ])\n",
    "\n",
    "let () = Juplot.draw ~fmt:`svg figure\n",
    "\n",
    "let figure (module P : Plot) =\n",
    "  P.heatmap\n",
    "    (`mat c)\n",
    "    ~style:\"image pixels\"\n",
    "    ([ barebone ]\n",
    "    @ [ title \"C\" ]\n",
    "    @ [ xlabel \"n\" ]\n",
    "    @ [ ylabel \"neurons\" ]\n",
    "    @ [ cbtics `auto ])\n",
    "\n",
    "let () = Juplot.draw ~fmt:`svg figure\n",
    "\n",
    "(*perform inference with these initial parameters*)\n",
    "let rates, all_us = get_us_and_rates prms prms trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the input over the course of optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let plot_us_init all_us i (module P : Plot) =\n",
    "  let it_title = Printf.sprintf \"Iteration %i\" i in\n",
    "  let u = List.nth_exn all_us i in\n",
    "  let u = AD.unpack_arr u |> fun z -> Arr.reshape z [| -1; 15 |] in\n",
    "  P.plots\n",
    "    (List.init 10 (fun i ->\n",
    "         let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "         item (A (Arr.get_slice [ []; [ i ] ] u)) ~style:st))\n",
    "    (default_props\n",
    "    @ [ xlabel \"time /ms\"\n",
    "      ; ylabel \"\"\n",
    "      ; title it_title\n",
    "      ; yrange (-0.03, 0.03)\n",
    "      ; set \"object rect from 0,-0.05 to 6,0.05 fc lt 2 fs transparent solid 0.3 front\"\n",
    "      ])\n",
    "\n",
    "let _ =\n",
    "  let open Gp in\n",
    "  let display_id = Jupyter_notebook.display \"text/html\" \"\" in\n",
    "  List.iter\n",
    "    (List.init (List.length all_us) ~f:(fun i -> i))\n",
    "    (fun phase ->\n",
    "      Juplot.draw ~fmt:`svg ~size:(500, 300) ~display_id (plot_us_init all_us phase);\n",
    "      Unix.sleepf 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the firing rates inferred initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let () =\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 50 (fun i ->\n",
    "           let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "           item (A (Arr.get_slice [ []; [ 2 * i ] ] rates)) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"rates\" ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With random initial parameters (no dynamics), iLQR fails to explain firing rates that explain the data well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let prms = Misc.load_bin \"progress_3500.params.bin\"\n",
    "let rates, all_us = get_us_and_rates prms prms trial\n",
    "\n",
    "let uf =\n",
    "  let open Dynamics.Mini_GRU_IO_P in\n",
    "  Owl_parameters.extract prms.generative.dynamics.uf |> AD.unpack_arr\n",
    "\n",
    "let c =\n",
    "  let open Likelihood.Poisson_P in\n",
    "  Owl_parameters.extract prms.generative.likelihood.c |> AD.unpack_arr\n",
    "\n",
    "let figure (module P : Plot) =\n",
    "  P.heatmap\n",
    "    (`mat uf)\n",
    "    ~style:\"image pixels\"\n",
    "    ([ barebone ] @ [ title \"Uf\" ] @ [ xlabel \"n\" ] @ [ ylabel \"n\" ] @ [ cbtics `auto ])\n",
    "\n",
    "let () = Juplot.draw ~fmt:`svg figure\n",
    "\n",
    "let figure (module P : Plot) =\n",
    "  P.heatmap\n",
    "    (`mat c)\n",
    "    ~style:\"image pixels\"\n",
    "    ([ barebone ] @ [ title \"C\" ] @ [ xlabel \"n\" ] @ [ ylabel \"n_o\" ] @ [ cbtics `auto ])\n",
    "\n",
    "let () = Juplot.draw ~fmt:`svg figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let plot_us_fin all_us i (module P : Plot) =\n",
    "  let it_title = Printf.sprintf \"Iteration %i\" i in\n",
    "  let u = List.nth_exn all_us i in\n",
    "  let u = AD.unpack_arr u |> fun z -> Arr.reshape z [| -1; 15 |] in\n",
    "  P.plots\n",
    "    (List.init 10 (fun i ->\n",
    "         let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "         item (A (Arr.get_slice [ []; [ i ] ] u)) ~style:st))\n",
    "    (default_props\n",
    "    @ [ xlabel \"time /ms\"; ylabel \"\"; title it_title; yrange (-0.1, 0.1) ]\n",
    "    @ [ set \"object rect from 0,-0.1 to 6,0.1 fc lt 2 fs transparent solid 0.3 front\" ])\n",
    "\n",
    "let _ =\n",
    "  let open Gp in\n",
    "  let display_id = Jupyter_notebook.display \"text/html\" \"\" in\n",
    "  List.iter\n",
    "    (List.init (List.length all_us) ~f:(fun i -> i))\n",
    "    (fun phase ->\n",
    "      Juplot.draw ~fmt:`svg ~size:(500, 300) ~display_id (plot_us_fin all_us phase);\n",
    "      Unix.sleepf 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Interestingly, even though iLQR-VAE assumes input-driven dynamics by default, here it fits the data using autonomous dynamics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let () =\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 50 (fun i ->\n",
    "           let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "           item (A (Arr.get_slice [ []; [ 2 * i ] ] rates)) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"rates\" ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible co-smoothing\n",
    "\n",
    "* A key advantage of iLQR-VAE is its **flexibility**\n",
    "\n",
    "* Given a set of generative parameters, inference can be performed on heterogeneous data\n",
    "\n",
    "* For instance we can train the model on all the neurons, but at test time evaluate the same model on a subset of the neurons by using **a subset of the readout matrix** to get the latents, and then predict firing rates for all neurons using the **full readout**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let eval_spikes_in = Arr.load_npy \"nlb/eval_spikes_in_0.npy\"\n",
    "let eval_spikes_out = Arr.load_npy \"nlb/eval_spikes_out_0.npy\"\n",
    "let n_neurons_eval = (Arr.shape eval_spikes_in).(2)\n",
    "\n",
    "let test_trial =\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let x =\n",
    "    Arr.get_slice [ [ 0 ] ] eval_spikes_in\n",
    "    |> fun z -> Arr.reshape z [| -1; n_train_neurons |]\n",
    "  in\n",
    "  let o = AD.pack_arr x in\n",
    "  Data.pack o\n",
    "\n",
    "(*select only the readout parameters of the held-in neurons*)\n",
    "\n",
    "let masked_prms =\n",
    "  let masked_likelihood ~prms =\n",
    "    let open Vae_typ.P in\n",
    "    let open Prior_typ in\n",
    "    let open Generative_typ.P in\n",
    "    let open Likelihood.Poisson_P in\n",
    "    let c = Owl_parameters.extract prms.c in\n",
    "    let bias = Owl_parameters.extract prms.bias in\n",
    "    let gain = Owl_parameters.extract prms.gain in\n",
    "    Likelihood.Poisson_P.\n",
    "      { c = pinned (AD.Maths.get_slice [ [ 0; n_train_neurons - 1 ] ] c)\n",
    "      ; bias = pinned (AD.Maths.get_slice [ []; [ 0; n_train_neurons - 1 ] ] bias)\n",
    "      ; c_mask = None\n",
    "      ; gain = pinned (AD.Maths.get_slice [ []; [ 0; n_train_neurons - 1 ] ] gain)\n",
    "      }\n",
    "  in\n",
    "  { generative =\n",
    "      { prior = prms.generative.prior\n",
    "      ; dynamics = prms.generative.dynamics\n",
    "      ; likelihood = masked_likelihood ~prms:prms.generative.likelihood\n",
    "      }\n",
    "  ; recognition = prms.recognition\n",
    "  }\n",
    "\n",
    "let rates, all_us = get_us_and_rates prms masked_prms test_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let () =\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 45 (fun i ->\n",
    "           let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "           item (A (Arr.get_slice [ []; [ 137 + i ] ] rates)) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"heldout neurons rates\" ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig\n",
    "\n",
    "let () =\n",
    "  let spikes_to_plot =\n",
    "    Arr.get_slice [ [ 0 ] ] eval_spikes_out\n",
    "    |> fun z -> Arr.reshape z [| -1; n_test_neurons |]\n",
    "  in\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 45 (fun i ->\n",
    "           let st = Printf.sprintf \"p pt 7 ps 0.4 lc %i\" i in\n",
    "           let fi = Float.of_int i in\n",
    "           let arr = Arr.get_slice [ []; [ i ] ] spikes_to_plot in\n",
    "           let arr = Arr.(fi $* arr) in\n",
    "           item (A arr) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"heldout neurons\"; yrange (0., 45.) ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible inference on heterogeneous time series\n",
    "\n",
    "* The flexible inference model can be used to fit *longer* or *shorter trials* than the data it was trained on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(*take only the first 50ms of the evaluation data *)\n",
    "let train_spikes_short = train_spikes |> fun z -> Arr.get_slice [ [ 0 ]; [ 0; 50 ] ] z\n",
    "\n",
    "let test_trial_short =\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let x = train_spikes_short |> fun z -> Arr.reshape z [| -1; n_neurons |] in\n",
    "  let o = AD.pack_arr x in\n",
    "  Data.pack o\n",
    "\n",
    "module R =\n",
    "  Recognition.ILQR (U) (D) (L)\n",
    "    (struct\n",
    "      let conv_threshold = 1E-6\n",
    "      let reuse_u = `never\n",
    "      let diag_time_cov = false\n",
    "      let n_steps = (Arr.shape train_spikes_short).(1)\n",
    "    end)\n",
    "\n",
    "let short_rates, _ =\n",
    "  let u_mean, all_us, zs =\n",
    "    let u_mean, all_us =\n",
    "      R.posterior_mean ~gen_prms:prms.generative prms.recognition test_trial_short\n",
    "    in\n",
    "    let u = AD.Maths.reshape u_mean [| 1; -1; AD.Mat.col_num u_mean |] in\n",
    "    let zs = G.integrate ~prms:prms.generative ~u in\n",
    "    let remove_n_beg = AD.Maths.get_slice [ []; [ G.n_beg - 1; -1 ] ] in\n",
    "    remove_n_beg u_mean, all_us, remove_n_beg zs\n",
    "  in\n",
    "  let z_mean =\n",
    "    Arr.mean ~axis:0 (AD.unpack_arr zs)\n",
    "    |> fun x -> Arr.reshape x [| -1; (Arr.shape x).(2) |]\n",
    "  in\n",
    "  let z_mean = AD.pack_arr z_mean in\n",
    "  let open Vae_typ.P in\n",
    "  let open Prior_typ in\n",
    "  let open Generative_typ.P in\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let c = Owl_parameters.extract prms.generative.likelihood.c in\n",
    "  let bias = Owl_parameters.extract prms.generative.likelihood.bias in\n",
    "  let gain = Owl_parameters.extract prms.generative.likelihood.gain in\n",
    "  AD.Maths.(F dt * gain * exp ((z_mean *@ transpose c) + bias)) |> AD.unpack_arr, all_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let () =\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 45 (fun i ->\n",
    "           let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "           item (A (Arr.get_slice [ []; [ 137 + i ] ] short_rates)) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"rates\" ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "OCaml 4.11.1+flambda",
   "language": "OCaml",
   "name": "ocaml-jupyter"
  },
  "language_info": {
   "codemirror_mode": "text/x-ocaml",
   "file_extension": ".ml",
   "mimetype": "text/x-ocaml",
   "name": "OCaml",
   "nbconverter_exporter": null,
   "pygments_lexer": "OCaml",
   "version": "4.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
