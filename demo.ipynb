{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iLQR-VAE tutorial \n",
    "\n",
    "In this tutorial, we will do the following : \n",
    "\n",
    "* Introduce the iLQR-VAE model\n",
    "* Illustrate usage of the method on one of the Neural Latents Benchmark datasets (the Maze dataset)\n",
    "* Illustrate how the flexible inference model can be used on heterogeneous data\n",
    "\n",
    "The code for the tutorial is in [Ocaml](https://ocaml.org) but no familiarity with the language is necessary to run the tutorial. Much of this tutorial is built on the [iLQR-VAE library](https://github.com/marineschimel/ilqr_vae)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iLQR-VAE overview\n",
    "\n",
    "\n",
    "iLQR-VAE is a method for inferring latent dynamics from noisy time series of observations.\n",
    "\n",
    "It does this by modelling the observations as the output of an *input-driven latent dynamical system*, whose latent trajectories are read out onto the observation space. \n",
    "\n",
    "The model is trained by optimizing the parameters to maximize the (marginal) likelihood of the data - essentially, this corresponds to learning the dynamical system that best explains the observations.\n",
    "\n",
    "As in any VAE, each learning iteration relies on the ability to perform inference for the current set of parameters. In iLQR-VAE, inference is performed using **iLQR**, a powerful optimization algorithm which rapidly converges to the inputs that best explain the data given the parameters. This results in a posterior over latent trajectories which forms the basis of a lower bound on the marginal likelihood -- the training objective.\n",
    "\n",
    "This differs from other similar methods (e.g LFADS) which instead learn the mapping from observations to latents using neural networks.\n",
    "\n",
    "The main advantages of iLQR-VAE is that it defines the mapping from data to latents *implicitly*, meaning that it has fewer hyperparameters to tune. This also makes training more robust, and inference more flexible (although not that there is no free lunch, and that the inference step in iLQR-VAE is typically slower than in e.g LFADS). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative process \n",
    "\n",
    "iLQR-VAE models observations (here, spike trains) as the output of an input-driven latent dynamical system (similarly to LFADS)\n",
    "\n",
    "\n",
    "<img src=\"figures/generative.png\" width=\"70%\"/>\n",
    "\n",
    "\n",
    "\n",
    "**Details of the generative model**\n",
    "* $\\theta$ are the parameters of the model\n",
    "\n",
    "* $\\mathbf{u}_t \\in \\mathbb{R}^m$, $\\mathbf{z}_t \\in \\mathbb{R}^n$ and $\\mathbf{o}_t \\in \\mathbb{R}^{n_o}$\n",
    "\n",
    "* Input-driven latent state dynamics : $\\mathbf{z}_{t+1} = f_\\theta(\\mathbf{z}_t, \\mathbf{u}_t, t)$ (note that the dynamics are deterministic given a set of inputs)\n",
    "\n",
    "* Likelihood given latents : $\\mathbf{o}_t | \\mathbf{z}_t \\sim p_\\theta(\\mathbf{o}_t | \\mathbf{z}_t)$\n",
    "\n",
    "* Student prior over the inputs (favouring *sparse inputs*) with a special Gaussian prior for the initial input (setting initial condition)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference procedure\n",
    "To train the model, we optimize $\\theta$ to maximize the marginal log-likelihood of observing a collection of independent observation sequences $\\mathbf{\\mathcal{O}} = \\{ \\mathbf{o}^{(1)}, \\ldots, \\mathbf{o}^{(K)} \\}$ (trials) given by:\n",
    "$$\n",
    "    \\log p_\\theta(\\mathbf{\\mathcal{O}})\n",
    "    =\n",
    "    \\sum_{k=1}^K\n",
    "    \\log \\int\n",
    "    p_\\theta(\\mathbf{o}^{(k)} |\\mathbf{z}(\\mathbf{u}))\n",
    "    p_\\theta(\\mathbf{u})\\,\n",
    "    d \\mathbf{u}\n",
    "$$\n",
    "\n",
    "Unfortunately, computing this expression is intractable. A common approach to deal with this problem is to introduce a new distribution $\\log q_\\phi(\\mathbf{u}|\\mathbf{o}^{(k)})$, typically chosen to be Gaussian, to approximate the posterior distribution $p_\\theta(\\mathbf{u}|\\mathbf{o}^{(k)})$. This then allows to write down a lower bound on the log-likelihood, called the ELBO :   \n",
    "$$\\mathcal{L}(\\mathbf{\\mathcal{O}}, \\theta, \\phi) =\n",
    "    \\sum_k\n",
    "    \\mathbb{E}_{q_\\phi(\\mathbf{u}|\\mathbf{o}^{(k)})}\n",
    "    \\left [\n",
    "        \\sum_{t=1}^T\n",
    "        \\underbrace{\\log p_\\theta(\\mathbf{o}_t^{(k)} | \\mathbf{z}_t)}_{\\text{reconstruction term}}\n",
    "        +\n",
    "         \\underbrace{\\log p_\\theta(\\mathbf{u}_t) - \n",
    "         \\log q_\\phi(\\mathbf{u}_t|\\mathbf{o}^{(k)}}_{\\text{regularization term}} )\\right]       \\\\\n",
    "        \\leq \\log p_\\theta(\\mathbf{\\mathcal{O}}).$$\n",
    "\n",
    "We thus also need an expression for $\\log q_\\phi(\\mathbf{u}_t|\\mathbf{o}^{(k)})$ : one common approach is to use a Gaussian approximation parameterized with (bi-)RNNs (as in LFADS). This has the disadvantage that it introduces new (hyper)-parameters into the model. Instead, we define $\\log q_\\phi(\\mathbf{u}_t|\\mathbf{o}^{(k)})$ to be centered at the *maximum of the true log posterior* $\\mathbf{u}^\\star$, defined as :\n",
    "        \n",
    " $$\\mathbf{u}^\\star(\\mathbf{o}^{(k)})\n",
    "      = \\underset{\\mathbf{u}}{\\text{argmax}}\\: \\log p_\\theta(\\mathbf{u}|\\mathbf{o}^{(k)}) \\\\\n",
    "      = \\underset{\\mathbf{u}}{\\text{argmax}} \\left[\n",
    "        \\sum_{t=1}^T \\log p_\\theta(\\mathbf{o}_t^{(k)} | \\mathbf{u})\n",
    "        + \\log p_\\theta(\\mathbf{u}_t)\n",
    "        \\right]$$\n",
    "        \n",
    "These inputs are now the solution of an optimization problem, which we solve using **iLQR**, a powerful algorithm from the control literature, such that \n",
    "$\\mathbf{u}^\\star(\\mathbf{o}) =\n",
    "    \\text{iLQRsolve}(\\mathbf{o}, \\theta).$\n",
    "\n",
    "iLQR solves for the inputs *iteratively* (more details can be found [here](https://jonathan-hui.medium.com/rl-lqr-ilqr-linear-quadratic-regulator-a5de5104c750)), and converges in a few iterations to a local optimum of the log posterior. \n",
    "\n",
    "This has the advantage that we don't need to introduce new parameters for the inference (at least for the mean), and reduces the number of hyperparameters to optimize. \n",
    "\n",
    "Finally, we define the covariance over of our approximate posterior $\\log q_\\phi$ as a Kronecker factorization of space and time covariances : $\\Sigma = \\Sigma_s \\bigotimes \\Sigma_t$. This is shared across all datapoints (i.e not amortized for each point). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model\n",
    "\n",
    "<img src=\"figures/model.png\" width=\"70%\"/>\n",
    "\n",
    "\n",
    "* The recognition model is defined *implicitly* through the generative parameters, yielding a compact model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustration of iLQR-VAE on the Maze dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use_output \"dune top\"\n",
    "\n",
    "open Owl\n",
    "open Ilqr_vae\n",
    "open Tutorial_lib\n",
    "open Gp\n",
    "open Owl_parameters\n",
    "open Base\n",
    "open Vae\n",
    "open Vae_typ.P\n",
    "open Functions\n",
    "open Tutorial_vae\n",
    "open Misc\n",
    "\n",
    "let () = print_msg \"Libraries loaded successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the generative model \n",
    "\n",
    "When we want to fit a model, we first need to define the generative model : this requires us to specify the prior over inputs, the likelihood function (i.e noise model) and the dynamics of the generator RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* Ocaml is a typed language: here, we define the parameters \n",
    "   that we will need to pass when setting up the model\n",
    "   (number of inputs, number of latents, size of the data) *)\n",
    "type setup =\n",
    "  { n : int\n",
    "  ; m : int\n",
    "  ; n_trials : int\n",
    "  ; n_steps : int\n",
    "  ; n_neural : int\n",
    "  ; dt : float\n",
    "  }\n",
    "\n",
    "let setup = { n = 90; m = 15; n_trials = 1; n_steps = 140; n_neural = 182; dt = 5E-3 }\n",
    "\n",
    "(* We use the inputs from iLQR to set both ongoing inputs and the initial condition. \n",
    "Because we have m inputs but the latent space is n-dimensional, we use inputs spread over\n",
    "several time bins to set the initial condition. More specifically, here we set n_beg = n/m\n",
    "which means we are using n/m time bins to set the initial condition. *)\n",
    "\n",
    "let n_beg = setup.n / setup.m\n",
    "\n",
    "(* Below, we specify which modules the model will consist of.\n",
    "   This corresponds to choosing specific forms for the prior, dynamics and likelihood. \n",
    "   This structure allows to quickly modify the model (e.g we could use a Gaussian prior, or\n",
    "   a vanilla RNN) by simply swapping one of the modules. *)\n",
    "\n",
    "(* Define the prior *)\n",
    "module U = Prior.Student (struct\n",
    "  let n_beg = n_beg\n",
    "  let m = setup.m\n",
    "end)\n",
    "\n",
    "(* Choose the type of likelihood (e.g Poisson for spikes, Gaussian for calcium imaging).\n",
    "   Although automatic differentiation is used throughout the library, here we define\n",
    "   the first and second derivatives of the link function explicitly as this enables\n",
    "   significant memory savings in iLQR (because Jacobians can be computed directly, thus\n",
    "   avoiding nested AD) *)\n",
    "\n",
    "module L = Likelihood.Poisson (struct\n",
    "  let label = \"neural\"\n",
    "  let dt = AD.F setup.dt\n",
    "  let link_function = AD.Maths.exp\n",
    "  let d_link_function = AD.Maths.exp\n",
    "  let d2_link_function = AD.Maths.exp\n",
    "  let n_output = setup.n_neural\n",
    "  let n = setup.n\n",
    "end)\n",
    "\n",
    "(* Choose the dynamics (e.g GRU RNN) *)\n",
    "module D = Dynamics.Mini_GRU_IO (struct\n",
    "  let phi x = AD.Maths.(AD.requad x - F 1.)\n",
    "  let d_phi x = AD.d_requad x\n",
    "  let sigma x = AD.Maths.sigmoid x\n",
    "  let d_sigma x = AD.Maths.(exp (neg x) / sqr (F 1. + exp (neg x)))\n",
    "  let m = setup.m\n",
    "  let n = setup.n\n",
    "  let n_beg = Some n_beg\n",
    "end)\n",
    "\n",
    "(* Define the hyperparameters for this dataset: latent space dimension n, number of input channels m *)\n",
    "module X = struct\n",
    "  let n = setup.n\n",
    "  let m = setup.m\n",
    "  let n_steps = setup.n_steps\n",
    "  let diag_time_cov = false\n",
    "  let n_beg = Some n_beg\n",
    "end\n",
    "\n",
    "(* remove a lot of boring outputs :) *)\n",
    "let () = Jupyter_notebook.clear_output ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the full model\n",
    "\n",
    "Next, we need to specify the recognition model. iLQR-VAE's main characteristic is the use of iLQR as an (implicitly defined) recognition model, however we could substitute this with e.g biRNNS, yielding a model similar to LFADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(* Our VAE is constructed by specifying (i) a generative model and (ii) a recognition model. *)\n",
    "\n",
    "(* Generative model *)\n",
    "module G = Generative.Make (U) (D) (L)\n",
    "\n",
    "(* Recognition model: iLQR; not that one could substitute other modules here\n",
    "   to recover e.g. something closer to LFADS *)\n",
    "module R =\n",
    "  Recognition.ILQR (U) (D) (L)\n",
    "    (struct\n",
    "      let conv_threshold = 1E-6\n",
    "      let reuse_u = `never\n",
    "      let diag_time_cov = false\n",
    "      let n_steps = setup.n_steps\n",
    "    end)\n",
    "\n",
    "module R1 = R\n",
    "module Model = Vae.Make (G) (R)\n",
    "\n",
    "let () = Jupyter_notebook.clear_output ()\n",
    "let () = print_msg \"Model defined successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "Here, we will illustrate the inference procedure of iLQR-VAE on a single trial from the Maze task. The full dataset can be downloaded at https://dandiarchive.org/#/dandiset/000128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let train_spikes = Arr.load_npy \"nlb/train_spikes_0.npy\"\n",
    "let n_train_neurons = 137\n",
    "let n_test_neurons = setup.n_neural - n_train_neurons\n",
    "\n",
    "let trial =\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let x =\n",
    "    Arr.get_slice [ [ 0 ] ] train_spikes\n",
    "    |> fun z -> Arr.reshape z [| -1; setup.n_neural |]\n",
    "  in\n",
    "  let o = AD.pack_arr x in\n",
    "  Data.pack o\n",
    "\n",
    "let () = Jupyter_notebook.clear_output ()\n",
    "let () = print_msg \"Data loaded successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data \n",
    "Below, we visualize 1 trial (out of 1721 trials used to train the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let () =\n",
    "  let spikes_to_plot =\n",
    "    Arr.get_slice [ [ 0 ] ] train_spikes\n",
    "    |> fun z -> Arr.reshape z [| -1; setup.n_neural |]\n",
    "  in\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 182 (fun i ->\n",
    "           let st = \"p pt 7 ps 0.2 lc black\" in\n",
    "           let fi = Float.of_int i in\n",
    "           let arr = Arr.get_slice [ []; [ i ] ] spikes_to_plot in\n",
    "           let arr = Arr.(fi $* arr) in\n",
    "           item (A arr) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"neuron\"; yrange (1., 182.) ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the data using iLQR-VAE : \n",
    "\n",
    "* Below, we will show how we use the iLQR-VAE model to fit these neural recordings.\n",
    "* In general, we will initialize a model with a set of random initial parameters, then train it for a few thousand iterations, and then evaluate the performance of the trained model.\n",
    "* Here, we will first look at the model at initialization. We will then skip most of the training step (a code snippet running a few iterations on a single CPU is provided as example, but the training is most efficient when parallelized over CPUs) and look at the results using a *pre-trained model*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of the model\n",
    "\n",
    "We initialize the model with random initial parameters. The dynamics are initially very weak. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (init_prms : Model.P.p) =\n",
    "  let generative =\n",
    "    let prior = U.init ~spatial_std:1.0 ~nu:20. learned in\n",
    "    let dynamics = D.init learned in\n",
    "    let likelihood = L.init learned in\n",
    "    Generative.P.{ prior; dynamics; likelihood }\n",
    "  in\n",
    "  let recognition = R1.init learned in\n",
    "  Model.init generative recognition\n",
    "\n",
    "let () = Jupyter_notebook.clear_output ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration of the inference with the initial parameters\n",
    "\n",
    "Below, we will use the random initial parameters to illustrate how we proceed to perform inference (and look at how an untrained model does at fitting the data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper function below is used to run the inference for a given set of parameters and trial. It finds the optimal inputs allowing the fit the data given the parameters. Latent trajectories and firing rates are then deterministic given a set of inputs. The function returns the inferred firing rates and inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let get_us_and_rates gen_prms prms trial =\n",
    "  (* get the posterior mean using iLQR; [all_us] will contain the whole\n",
    "     sequence of control input as it's being optimised through consecutive\n",
    "     LQR iterations; cf. movie below *)\n",
    "  let u_mean, all_us =\n",
    "    R.posterior_mean ~gen_prms:prms.generative prms.recognition trial\n",
    "  in\n",
    "  let rates =\n",
    "    G.sample ~prms:gen_prms.generative ~pre:true (`some AD.(expand_to_3d u_mean))\n",
    "    |> Data.o\n",
    "    |> AD.unpack_arr\n",
    "  in\n",
    "  (*(* for a given set of inputs, the latents are obtained by running the dynamics forward *)\n",
    "    let zs = G.integrate ~prms:prms.generative ~u:(AD.expand_to_3d u_mean) in\n",
    "    (* we infer the initial condition through the first inputs in the sequence : this \n",
    "       means the first time bins of the latent trajectory are meaningless and need to be removed *)\n",
    "    let remove_n_beg = AD.Maths.get_slice [ []; [ G.n_beg - 1; -1 ] ] in\n",
    "    remove_n_beg u_mean, all_us, remove_n_beg zs\n",
    "  in\n",
    "  let z_mean =\n",
    "    Arr.mean ~axis:0 (AD.unpack_arr zs)\n",
    "    |> fun x -> Arr.reshape x [| -1; (Arr.shape x).(2) |]\n",
    "  in\n",
    "  let z_mean = AD.pack_arr z_mean in\n",
    "  let open Vae_typ.P in\n",
    "  let open Prior_typ in\n",
    "  let open Generative_typ.P in\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let rates =\n",
    "    L.pre_sample ~prms:gen_prms.generative.likelihood ~z:z_mean |> AD.unpack_arr\n",
    "  in *)\n",
    "  rates, all_us\n",
    "\n",
    "let () = Jupyter_notebook.clear_output ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the initial input\n",
    "\n",
    "iLQR-VAE fits the data by inferring the input that best explains the observations given a set of generative parameters. iLQR solves this problem *iteratively*, by converging in a few iterations to the locally optimal input. Below, we show the evolution of the input over the course of the convergence of iLQR (note that these iterations are different from training iterations, they occur during the inference procedure). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let rates =\n",
    "  (* perform inference using these initial (bad!) parameters *)\n",
    "  let rates, all_us = get_us_and_rates init_prms init_prms trial in\n",
    "  let open Gp in\n",
    "  let display_id = Jupyter_notebook.display \"text/html\" \"\" in\n",
    "  List.iter\n",
    "    (List.init (List.length all_us) ~f:(fun i -> i))\n",
    "    (fun phase ->\n",
    "      Juplot.draw\n",
    "        ~fmt:`svg\n",
    "        ~size:(500, 300)\n",
    "        ~display_id\n",
    "        (Functions.plot_us_init all_us phase);\n",
    "      Unix.sleepf 0.6);\n",
    "  rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the beginning of training, the model infers very unstructured inputs throughout the whole trial. This reflects the prior, which initially has the same variance for the first time bin and the rest of the trial, and which is very close to Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...and corresponding firing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let fig (module P : Plot) =\n",
    "  P.plots\n",
    "    (List.init 50 (fun i ->\n",
    "         let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "         item (A (Arr.get_slice [ []; [ 2 * i ] ] rates)) ~style:st))\n",
    "    (default_props @ [ xlabel \"time /ms\"; ylabel \"rates\" ])\n",
    "in\n",
    "Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the very weak initial dynamics and random readout, and despite the fact that it's driven by inputs, the model completely fails to fit the data. The latents all decay very quickly to 0 (leading to firing rates decaying to 1). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training procedure \n",
    "\n",
    "* We need to learn the **generative** parameters of the model and the **posterior covariance**\n",
    "* This is done by optimizing the ELBO.\n",
    "* To train the model, we use Adam with a sqrt decaying learning rate. \n",
    "* The learning rate, as well as the size of the latent state and the dimension of the inputs are *hyperparameters which need to be tuned*.\n",
    "* We parallelize the training over CPUs; it typically takes ~6-8h on 168 CPUs with a batch size of 168. Note that it can be run on a lot fewer CPUs (ideally setting the mini_batch size to be equal or a multiple of the number of CPUs). Using smaller batches comes at the cost of noisier gradient estimates.\n",
    "* Below, we will illustrate how to a run few training iterations of iLQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let train_data, test_data =\n",
    "  let data =\n",
    "    lazy\n",
    "      [| Data.pack\n",
    "           (AD.pack_arr\n",
    "              (Arr.reshape\n",
    "                 (Arr.load_npy \"nlb/train_spikes_0.npy\")\n",
    "                 [| -1; setup.n_neural |]))\n",
    "       ; Data.pack (AD.pack_arr (Arr.load_npy \"nlb/eval_spikes_in_0.npy\"))\n",
    "      |]\n",
    "  in\n",
    "  Data.split_and_distribute ~reuse:false ~prefix:\"data\" ~train:1 data\n",
    "\n",
    "let final_prms =\n",
    "  Model.train\n",
    "    ~n_posterior_samples:(fun _iter -> 1)\n",
    "    ~max_iter:5\n",
    "    ~learning_rate:(`of_iter (fun iter -> Float.(0.004 / (1. + sqrt (of_int iter / 1.)))))\n",
    "    ~init_prms\n",
    "    train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After training \n",
    "\n",
    "Now we will assume we had time to run 3500 iterations, and repeat the inference procedure with the parameters of the model *after training*. We will load parameters of the model after 3500 iterations, and evaluate the inferred firing rates and inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let prms = Misc.load_bin \"final_params.bin\"\n",
    "let rates, all_us = get_us_and_rates prms prms trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let plot_us_fin all_us i (module P : Plot) =\n",
    "  let it_title = Printf.sprintf \"Iteration %i\" i in\n",
    "  let u = List.nth_exn all_us i in\n",
    "  let u = AD.unpack_arr u |> fun z -> Arr.reshape z [| -1; 15 |] in\n",
    "  P.plots\n",
    "    (List.init 10 (fun i ->\n",
    "         let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "         item (A (Arr.get_slice [ []; [ i ] ] u)) ~style:st))\n",
    "    (default_props\n",
    "    @ [ xlabel \"time /ms\"; ylabel \"\"; title it_title; yrange (-0.1, 0.1) ]\n",
    "    @ [ set \"object rect from 0,-0.1 to 6,0.1 fc lt 2 fs transparent solid 0.3 front\" ])\n",
    "\n",
    "let _ =\n",
    "  let open Gp in\n",
    "  let display_id = Jupyter_notebook.display \"text/html\" \"\" in\n",
    "  List.iter\n",
    "    (List.init (List.length all_us) ~f:(fun i -> i))\n",
    "    (fun phase ->\n",
    "      Juplot.draw ~fmt:`svg ~size:(500, 300) ~display_id (plot_us_fin all_us phase);\n",
    "      Unix.sleepf 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model relies *only on the initial condition* to fit the observations. This is consistent with previous findings that the dynamics of the Maze dataset are well-described by an autonomous dynamical system (Pandarinath et al, 2018). \n",
    "Interestingly, this happens here despite iLQR-VAE assuming input-driven dynamics by default, suggesting that with this choice of generative model, the \"best model\" is one evolving autonomously from the initial condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferring the firing rates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let () =\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 50 (fun i ->\n",
    "           let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "           item (A (Arr.get_slice [ []; [ 2 * i ] ] rates)) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"rates\" ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the firing rates look a lot more reasonable - to evaluate quantitatively how well the model captures the observations, we will assess performance on co-smoothing below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible co-smoothing\n",
    "\n",
    "* A key advantage of iLQR-VAE is the flexibility of its inference model\n",
    "\n",
    "* Given a set of generative parameters, inference can be performed on heterogeneous data\n",
    "\n",
    "* This allows to evaluate co-smoothing (predictions of held-out spikes from held-in data) straightforwardly. We train the model on all the neurons, but at test time we evaluate the same model on a subset of held-in neurons by using **a subset of the readout matrix** to infer the latents from the partial observations. We then predict firing rates for all neurons using the **full readout**\n",
    "\n",
    "\n",
    "<img src=\"figures/co_smoothing_training.png\" width=\"100%\"/>\n",
    "\n",
    "<img src=\"figures/co_smoothing_testing.png\" width=\"100%\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(*here, we load a new trial for evaluation of the model : the model will only be shown the held-in spikes, but it \n",
    "will make predictions for the firing rates of the whole population*)\n",
    "\n",
    "let eval_spikes_in = Arr.load_npy \"nlb/eval_spikes_in_0.npy\"\n",
    "let eval_spikes_out = Arr.load_npy \"nlb/eval_spikes_out_0.npy\"\n",
    "let n_neurons_eval = (Arr.shape eval_spikes_in).(2)\n",
    "\n",
    "let test_trial =\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let x =\n",
    "    Arr.get_slice [ [ 0 ] ] eval_spikes_in\n",
    "    |> fun z -> Arr.reshape z [| -1; n_train_neurons |]\n",
    "  in\n",
    "  let o = AD.pack_arr x in\n",
    "  Data.pack o\n",
    "\n",
    "(*select only the readout parameters of the held-in neurons*)\n",
    "\n",
    "let masked_prms =\n",
    "  let masked_likelihood ~prms =\n",
    "    let open Vae_typ.P in\n",
    "    let open Prior_typ in\n",
    "    let open Generative_typ.P in\n",
    "    let open Likelihood.Poisson_P in\n",
    "    let c = Owl_parameters.extract prms.c in\n",
    "    let bias = Owl_parameters.extract prms.bias in\n",
    "    let gain = Owl_parameters.extract prms.gain in\n",
    "    Likelihood.Poisson_P.\n",
    "      { c = pinned (AD.Maths.get_slice [ [ 0; n_train_neurons - 1 ] ] c)\n",
    "      ; bias = pinned (AD.Maths.get_slice [ []; [ 0; n_train_neurons - 1 ] ] bias)\n",
    "      ; c_mask = None\n",
    "      ; gain = pinned (AD.Maths.get_slice [ []; [ 0; n_train_neurons - 1 ] ] gain)\n",
    "      }\n",
    "  in\n",
    "  { generative =\n",
    "      { prior = prms.generative.prior\n",
    "      ; dynamics = prms.generative.dynamics\n",
    "      ; likelihood = masked_likelihood ~prms:prms.generative.likelihood\n",
    "      }\n",
    "  ; recognition = prms.recognition\n",
    "  }\n",
    "\n",
    "let rates, all_us = get_us_and_rates prms masked_prms test_trial\n",
    "let () = Jupyter_notebook.clear_output ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let () =\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 45 (fun i ->\n",
    "           let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "           item (A (Arr.get_slice [ []; [ 137 + i ] ] rates)) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"heldout neurons rates\" ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig\n",
    "\n",
    "let () =\n",
    "  let spikes_to_plot =\n",
    "    Arr.get_slice [ [ 0 ] ] eval_spikes_out\n",
    "    |> fun z -> Arr.reshape z [| -1; n_test_neurons |]\n",
    "  in\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 45 (fun i ->\n",
    "           let st = Printf.sprintf \"p pt 7 ps 0.4 lc %i\" i in\n",
    "           let fi = Float.of_int i in\n",
    "           let arr = Arr.get_slice [ []; [ i ] ] spikes_to_plot in\n",
    "           let arr = Arr.(fi $* arr) in\n",
    "           item (A arr) ~style:st))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"heldout neurons\"; yrange (0., 45.) ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate co-smoothing quantitatively, we can then compute how much better the model predicts observed spikes than a baseline that models each firing rate as the average rate for that neuron. \n",
    "Over the whole validation set (1/574 trials here), iLQR-VAE yields a co-smoothing of 0.354, suggesting that it captures the dynamics very well after learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexible inference on heterogeneous time series\n",
    "\n",
    "* The flexible inference model can also be used to fit *longer* or *shorter trials* than the data it was trained on\n",
    "\n",
    "* This is different from biRNNs which need to take in data sequences from the same length as the ones they were trained on\n",
    "\n",
    "* Below, we illustrate this by fitting the model using the whole time series, the first 100ms of the trial, and the first 50ms only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(*take only the first 50ms of the evaluation data *)\n",
    "let train_spikes_short_1 = train_spikes |> fun z -> Arr.get_slice [ [ 0 ]; [ 0; -1 ] ] z\n",
    "let train_spikes_short_2 = train_spikes |> fun z -> Arr.get_slice [ [ 0 ]; [ 0; 99 ] ] z\n",
    "let train_spikes_short_3 = train_spikes |> fun z -> Arr.get_slice [ [ 0 ]; [ 0; 49 ] ] z\n",
    "\n",
    "let test_trial_short_1, test_trial_short_2, test_trial_short_3 =\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let reshape x = Arr.reshape x [| -1; setup.n_neural |] in\n",
    "  let o1 = train_spikes_short_1 |> reshape |> AD.pack_arr in\n",
    "  let o2 = train_spikes_short_2 |> reshape |> AD.pack_arr in\n",
    "  let o3 = train_spikes_short_3 |> reshape |> AD.pack_arr in\n",
    "  Data.pack o1, Data.pack o2, Data.pack o3\n",
    "\n",
    "module R1 =\n",
    "  Recognition.ILQR (U) (D) (L)\n",
    "    (struct\n",
    "      let conv_threshold = 1E-6\n",
    "      let reuse_u = `never\n",
    "      let diag_time_cov = false\n",
    "      let n_steps = (Arr.shape train_spikes_short_1).(1)\n",
    "    end)\n",
    "\n",
    "module R2 =\n",
    "  Recognition.ILQR (U) (D) (L)\n",
    "    (struct\n",
    "      let conv_threshold = 1E-6\n",
    "      let reuse_u = `never\n",
    "      let diag_time_cov = false\n",
    "      let n_steps = (Arr.shape train_spikes_short_2).(1)\n",
    "    end)\n",
    "\n",
    "module R3 =\n",
    "  Recognition.ILQR (U) (D) (L)\n",
    "    (struct\n",
    "      let conv_threshold = 1E-6\n",
    "      let reuse_u = `never\n",
    "      let diag_time_cov = false\n",
    "      let n_steps = (Arr.shape train_spikes_short_3).(1)\n",
    "    end)\n",
    "\n",
    "let rates test_trial_short num =\n",
    "  let u_mean, all_us, zs =\n",
    "    let u_mean, all_us =\n",
    "      if num = 1\n",
    "      then R1.posterior_mean ~gen_prms:prms.generative prms.recognition test_trial_short\n",
    "      else if num = 2\n",
    "      then R2.posterior_mean ~gen_prms:prms.generative prms.recognition test_trial_short\n",
    "      else R3.posterior_mean ~gen_prms:prms.generative prms.recognition test_trial_short\n",
    "    in\n",
    "    let u = AD.Maths.reshape u_mean [| 1; -1; AD.Mat.col_num u_mean |] in\n",
    "    let zs = G.integrate ~prms:prms.generative ~u in\n",
    "    let remove_n_beg = AD.Maths.get_slice [ []; [ G.n_beg - 1; -1 ] ] in\n",
    "    remove_n_beg u_mean, all_us, remove_n_beg zs\n",
    "  in\n",
    "  let z_mean =\n",
    "    Arr.mean ~axis:0 (AD.unpack_arr zs)\n",
    "    |> fun x -> Arr.reshape x [| -1; (Arr.shape x).(2) |]\n",
    "  in\n",
    "  let z_mean = AD.pack_arr z_mean in\n",
    "  let open Vae_typ.P in\n",
    "  let open Prior_typ in\n",
    "  let open Generative_typ.P in\n",
    "  let open Likelihood.Poisson_P in\n",
    "  let c = Owl_parameters.extract prms.generative.likelihood.c in\n",
    "  let bias = Owl_parameters.extract prms.generative.likelihood.bias in\n",
    "  let gain = Owl_parameters.extract prms.generative.likelihood.gain in\n",
    "  AD.Maths.(gain * exp ((z_mean *@ transpose c) + bias)) |> AD.unpack_arr\n",
    "\n",
    "let rates1, rates2, rates3 =\n",
    "  rates test_trial_short_1 1, rates test_trial_short_2 2, rates test_trial_short_2 3\n",
    "\n",
    "let () = Jupyter_notebook.clear_output ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let () =\n",
    "  let fig (module P : Plot) =\n",
    "    P.plots\n",
    "      (List.init 30 (fun i ->\n",
    "           if i < 10\n",
    "           then (\n",
    "             let st = Printf.sprintf \"l lw 2 lc %i\" i in\n",
    "             item (A (Arr.get_slice [ []; [ 2 * i ] ] rates1)) ~style:st)\n",
    "           else if i < 20\n",
    "           then (\n",
    "             let st = Printf.sprintf \"l lw 2 lc %i dt 2\" Int.(i - 10) in\n",
    "             item (A (Arr.get_slice [ []; [ (2 * Int.(i - 10)) ] ] rates2)) ~style:st)\n",
    "           else (\n",
    "             let st = Printf.sprintf \"l lw 2 lc %i dt 3\" Int.(i - 20) in\n",
    "             item (A (Arr.get_slice [ []; [ (2 * Int.(i - 20)) ] ] rates3)) ~style:st)))\n",
    "      (default_props @ [ xlabel \"time /ms\"; ylabel \"rates\" ])\n",
    "  in\n",
    "  Juplot.draw ~fmt:`svg ~size:(500, 300) fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inferred rates are similar for the different time windows used. In general, one would expect the inferred rates to be more accurate for larger time windows, as more information is available to find the firing rates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We've reached the end of the tutorial!  In summary : \n",
    "* iLQR-VAE is a method that models noisy observations as the output of an input-driven dynamical system.\n",
    "* Unlike other methods (e.g LFADS) it uses an implicit, optimization-based recognition model, allowing for flexible inference and robust training.\n",
    "* Here, we have looked more closely at how the inference procedure works, and shown that iLQR-VAE fits the neural recordings from the Maze dataset very well (here, measured using the co-smoothing metric).\n",
    "* Finally, we have shown how iLQR-VAE can be used on heterogeneous data.\n",
    "\n",
    "Thanks for following through! More details on the method can be found at in [the paper](https://www.biorxiv.org/content/10.1101/2021.10.07.463540v1.article-metrics) and I'm happy to answer any questions [by email](mailto:mmcs3@cam.ac.uk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "OCaml 4.11.1+flambda",
   "language": "OCaml",
   "name": "ocaml-jupyter"
  },
  "language_info": {
   "codemirror_mode": "text/x-ocaml",
   "file_extension": ".ml",
   "mimetype": "text/x-ocaml",
   "name": "OCaml",
   "nbconverter_exporter": null,
   "pygments_lexer": "OCaml",
   "version": "4.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
